{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Binder 驱动概述\n",
    "### 1.1 概述\n",
    "- Binder 驱动是 Android 专用的，但底层的驱动架构与 Linux 驱动一样。binder 驱动在以 misc 设备进行注册，作为虚拟字符设备，没有直接操作硬件，只是对设备内存的处理。主要是驱动设备的初始化(binder_init)，打开 (binder_open)，映射(binder_mmap)，数据操作(binder_ioctl)。\n",
    "\n",
    "![image](binder1_page1.png)\n",
    "\n",
    "### 1.2 系统调用\n",
    "- 用户态的程序调用 Kernel 层驱动是需要陷入内核态，进行系统调用(syscall)，比如打开 Binder 驱动方法的调用链为： open-> __ open() -> binder_open()。 open() 为用户空间的方法，__open() 便是系统调用中相应的处理方法，通过查找，对应调用到内核 binder 驱动的 binder_open() 方法，至于其他的从用户态陷入内核态的流程也基本一致。\n",
    "\n",
    "![image](binder1_page2.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Binder 核心方法\n",
    "### 2.1 binder_init\n",
    "- 主要工作是为了注册 misc 设备\n",
    "- debugfs_create_dir 是指在 debugfs 文件系统中创建一个目录，返回值是指向 dentry 的指针。当 kernel 中禁用 debugfs 的话，返回值是 -%ENODEV。默认是禁用的。如果需要打开，在目录 /kernel/arch/arm64/configs/ 下找到目标 defconfig 文件中添加一行 CONFIG_DEBUG_FS=y，再重新编译版本，即可打开 debug_fs。\n",
    "\n",
    "```\n",
    "static int __init binder_init(void)\n",
    "{\n",
    "    int ret;\n",
    "    // 创建名为 binder 的工作队列\n",
    "    binder_deferred_workqueue = create_singlethread_workqueue(\"binder\");\n",
    "    ...\n",
    "\n",
    "    binder_debugfs_dir_entry_root = debugfs_create_dir(\"binder\", NULL);\n",
    "    if (binder_debugfs_dir_entry_root)\n",
    "        binder_debugfs_dir_entry_proc = debugfs_create_dir(\"proc\",\n",
    "                         binder_debugfs_dir_entry_root);\n",
    "\n",
    "     // 注册 misc 设备【见小节2.1.1】\n",
    "    ret = misc_register(&binder_miscdev);\n",
    "    if (binder_debugfs_dir_entry_root) {\n",
    "        ... // 在 debugfs 文件系统中创建一系列的文件\n",
    "    }\n",
    "    return ret;\n",
    "}\n",
    "```\n",
    "\n",
    "#### 2.1.1 misc_register\n",
    "- 注册 misc 设备，miscdevice 结构体，便是前面注册 misc 设备时传递进去的参数\n",
    "\n",
    "```\n",
    "static struct miscdevice binder_miscdev = {\n",
    "    .minor = MISC_DYNAMIC_MINOR, // 次设备号 动态分配\n",
    "    .name = \"binder\",            // 设备名\n",
    "    .fops = &binder_fops         // 设备的文件操作结构，这是 file_operations 结构\n",
    "};\n",
    "```\n",
    "\n",
    "- file_operations 结构体, 指定相应文件操作的方法\n",
    "```\n",
    "static const struct file_operations binder_fops = {\n",
    "    .owner = THIS_MODULE,\n",
    "    .poll = binder_poll,\n",
    "    .unlocked_ioctl = binder_ioctl,\n",
    "    .compat_ioctl = binder_ioctl,\n",
    "    .mmap = binder_mmap,\n",
    "    .open = binder_open,\n",
    "    .flush = binder_flush,\n",
    "    .release = binder_release,\n",
    "};\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 binder_open\n",
    "- 打开 binder 驱动设备\n",
    "\n",
    "```\n",
    "static int binder_open(struct inode *nodp, struct file *filp)\n",
    "{\n",
    "    struct binder_proc *proc;   // binder 进程 【见附录3.1】\n",
    "\n",
    "    proc = kzalloc(sizeof(*proc), GFP_KERNEL); // 为 binder_proc 结构体在分配 kernel 内存空间\n",
    "    if (proc == NULL)\n",
    "        return -ENOMEM;\n",
    "    get_task_struct(current);\n",
    "    proc->tsk = current;          // 将当前线程的 task 保存到 binder 进程的 tsk\n",
    "    INIT_LIST_HEAD(&proc->todo);  // 初始化 todo 列表\n",
    "    init_waitqueue_head(&proc->wait); // 初始化 wait 队列\n",
    "    proc->default_priority = task_nice(current);  // 将当前进程的 nice 值转换为进程优先级\n",
    "\n",
    "    binder_lock(__func__);   // 同步锁，因为binder支持多线程访问\n",
    "    binder_stats_created(BINDER_STAT_PROC); // BINDER_PROC 对象创建数加1\n",
    "    hlist_add_head(&proc->proc_node, &binder_procs); // 将 proc_node 节点添加到 binder_procs 为表头的队列\n",
    "    proc->pid = current->group_leader->pid;\n",
    "    INIT_LIST_HEAD(&proc->delivered_death); // 初始化已分发的死亡通知列表\n",
    "    filp->private_data = proc;        // file 文件指针的 private_data 变量指向 binder_proc 数据\n",
    "    binder_unlock(__func__);          // 释放同步锁\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "- 创建 binder_proc 对象，并把当前进程等信息保存到 binder_proc 对象，该对象管理 IPC 所需的各种信息并拥有其他结构体的根结构体；再把 binder_proc 对象保存到文件指针 filp，以及把 binder_proc 加入到全局链表 binder_procs。\n",
    "- Binder 驱动中通过 static HLIST_HEAD(binder_procs);，创建了全局的哈希链表 binder_procs，用于保存所有的 binder_proc 队列，每次新创建的 binder_proc 对象都会加入 binder_procs 链表中。\n",
    "![image](binder1_page3.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 binder_mmap\n",
    "- 主要功能：首先在内核虚拟地址空间，申请一块与用户虚拟内存相同大小的内存；然后再申请1个 page 大小的物理内存，再将同一块物理内存分别映射到内核虚拟地址空间和用户虚拟内存空间，从而实现了用户空间的 Buffer 和内核空间的 Buffer 同步操作的功能。\n",
    "\n",
    "```\n",
    "static int binder_mmap(struct file *filp, struct vm_area_struct *vma)\n",
    "{\n",
    "    int ret;\n",
    "    struct vm_struct *area; //内核虚拟空间\n",
    "    struct binder_proc *proc = filp->private_data;\n",
    "    const char *failure_string;\n",
    "    struct binder_buffer *buffer;  //【见附录3.9】\n",
    "\n",
    "    if (proc->tsk != current)\n",
    "        return -EINVAL;\n",
    "\n",
    "    if ((vma->vm_end - vma->vm_start) > SZ_4M)\n",
    "        vma->vm_end = vma->vm_start + SZ_4M;  //保证映射内存大小不超过4M\n",
    "\n",
    "    mutex_lock(&binder_mmap_lock);  //同步锁\n",
    "    //采用IOREMAP方式，分配一个连续的内核虚拟空间，与进程虚拟空间大小一致\n",
    "    area = get_vm_area(vma->vm_end - vma->vm_start, VM_IOREMAP);\n",
    "    if (area == NULL) {\n",
    "        ret = -ENOMEM;\n",
    "        failure_string = \"get_vm_area\";\n",
    "        goto err_get_vm_area_failed;\n",
    "    }\n",
    "    proc->buffer = area->addr; //指向内核虚拟空间的地址\n",
    "    //地址偏移量 = 用户虚拟地址空间 - 内核虚拟地址空间\n",
    "    proc->user_buffer_offset = vma->vm_start - (uintptr_t)proc->buffer;\n",
    "    mutex_unlock(&binder_mmap_lock); //释放锁\n",
    "\n",
    "    ...\n",
    "    //分配物理页的指针数组，数组大小为vma的等效page个数；\n",
    "    proc->pages = kzalloc(sizeof(proc->pages[0]) * ((vma->vm_end - vma->vm_start) / PAGE_SIZE), GFP_KERNEL);\n",
    "    if (proc->pages == NULL) {\n",
    "        ret = -ENOMEM;\n",
    "        failure_string = \"alloc page array\";\n",
    "        goto err_alloc_pages_failed;\n",
    "    }\n",
    "    proc->buffer_size = vma->vm_end - vma->vm_start;\n",
    "\n",
    "    vma->vm_ops = &binder_vm_ops;\n",
    "    vma->vm_private_data = proc;\n",
    "\n",
    "    //分配物理页面，同时映射到内核空间和进程空间，先分配1个物理页 【见小节2.3.1】\n",
    "    if (binder_update_page_range(proc, 1, proc->buffer, proc->buffer + PAGE_SIZE, vma)) {\n",
    "        ret = -ENOMEM;\n",
    "        failure_string = \"alloc small buf\";\n",
    "        goto err_alloc_small_buf_failed;\n",
    "    }\n",
    "    buffer = proc->buffer; //binder_buffer对象 指向proc的buffer地址\n",
    "    INIT_LIST_HEAD(&proc->buffers); //创建进程的buffers链表头\n",
    "    list_add(&buffer->entry, &proc->buffers); //将binder_buffer地址 加入到所属进程的buffers队列\n",
    "    buffer->free = 1;\n",
    "    //将空闲buffer放入proc->free_buffers中\n",
    "    binder_insert_free_buffer(proc, buffer);\n",
    "    //异步可用空间大小为buffer总大小的一半。\n",
    "    proc->free_async_space = proc->buffer_size / 2;\n",
    "    barrier();\n",
    "    proc->files = get_files_struct(current);\n",
    "    proc->vma = vma;\n",
    "    proc->vma_vm_mm = vma->vm_mm;\n",
    "    return 0;\n",
    "\n",
    "    ...// 错误flags跳转处，free释放内存之类的操作\n",
    "    return ret;\n",
    "}\n",
    "```\n",
    "\n",
    "- binder_mmap 通过加锁，保证一次只有一个进程分配内存，保证多进程间的并发访问。其中 user_buffer_offset 是虚拟进程地址与虚拟内核地址的差值(该值为负数)。也就是说同一物理地址，当内核地址为 kernel_addr，则进程地址为 proc_addr = kernel_addr + user_buffer_offset。\n",
    "\n",
    "#### 2.3.1 binder_update_page_range\n",
    "\n",
    "```\n",
    "static int binder_update_page_range(struct binder_proc *proc, int allocate,\n",
    "            void *start, void *end,\n",
    "            struct vm_area_struct *vma)\n",
    "{\n",
    "  void *page_addr;\n",
    "  unsigned long user_page_addr;\n",
    "  struct page **page;\n",
    "  struct mm_struct *mm; // 内存结构体\n",
    "\n",
    "  if (vma)\n",
    "  \t\tmm = NULL; // binder_mmap 过程 vma 不为空，其他情况都为空\n",
    "  \telse\n",
    "  \t\tmm = get_task_mm(proc->tsk); // 获取 mm 结构体\n",
    "      \n",
    "  if (mm) {\n",
    "    down_write(&mm->mmap_sem); // 获取 mm_struct 的写信号量\n",
    "    vma = proc->vma;\n",
    "  }\n",
    "\n",
    "  // 此处 allocate 为 1，代表分配过程。如果为 0 则代表释放过程\n",
    "  if (allocate == 0)\n",
    "    goto free_range;\n",
    "\n",
    "  for (page_addr = start; page_addr < end; page_addr += PAGE_SIZE) {\n",
    "    int ret;\n",
    "    page = &proc->pages[(page_addr - proc->buffer) / PAGE_SIZE];\n",
    "    // 分配一个page的物理内存\n",
    "    *page = alloc_page(GFP_KERNEL | __GFP_HIGHMEM | __GFP_ZERO);\n",
    "    \n",
    "    // 物理空间映射到虚拟内核空间\n",
    "    ret = map_kernel_range_noflush((unsigned long)page_addr,\n",
    "          PAGE_SIZE, PAGE_KERNEL, page);\n",
    "    flush_cache_vmap((unsigned long)page_addr, (unsigned long)page_addr + PAGE_SIZE);\n",
    "  \n",
    "    user_page_addr = (uintptr_t)page_addr + proc->user_buffer_offset;\n",
    "    // 物理空间映射到虚拟进程空间\n",
    "    ret = vm_insert_page(vma, user_page_addr, page[0]);\n",
    "  }\n",
    "  \n",
    "  if (mm) {\n",
    "    up_write(&mm->mmap_sem); // 释放内存的写信号量\n",
    "    mmput(mm); // 减少mm->mm_users计数\n",
    "  }\n",
    "  return 0;\n",
    "\n",
    "free_range:\n",
    "  ... // 释放内存的流程\n",
    "  \n",
    "  return -ENOMEM;\n",
    "}\n",
    "```\n",
    "\n",
    "![image](binder1_page4.png)\n",
    "\n",
    "- 主要工作如下：\n",
    "  - binder_update_page_range 主要完成工作：分配物理空间，将物理空间映射到内核空间，将物理空间映射到进程空间。另外，不同参数下该方法也可以释放物理页面。\n",
    "\n",
    "- binder_update_page_range 的调用时机：\n",
    "  - binder_mmap: 用于分配内存，分配大小为 1 page, vma 不为空\n",
    "  - binder_alloc_buf：用于分配内存，vma 为空\n",
    "  - binder_free_buf: 用于释放内存，vma 为空\n",
    "  - binder_delete_free_buffer：同样用于释放内存，vma 为空\n",
    "  \n",
    "- mm_struct 结构体，定义在 mm_types.h 文件：\n",
    "\n",
    "```\n",
    "struct mm_struct {\n",
    "  struct vm_area_struct *mmap;   // VMA 列表\n",
    "  struct rb_root mm_rb;\n",
    "  pgd_t * pgd;\n",
    "  atomic_t mm_users;             // 使用该内存的进程个数\n",
    "  atomic_t mm_count;             // 结构体 mm_struct 的引用个数\n",
    "  struct rw_semaphore mmap_sem;  // 读写信号量，用于同步\n",
    "  unsigned long flags; \n",
    "  ...\n",
    "};\n",
    "```\n",
    "\n",
    "#### 2.3.2 binder_alloc_buf\n",
    "- 通过 binder_alloc_buf() 方法来分配 binder_buffer 结构体, 只有在 binder_transaction 过程才需要分配 buffer。\n",
    "\n",
    "```\n",
    "static struct binder_buffer *binder_alloc_buf(struct binder_proc *proc,\n",
    "                          size_t data_size, size_t offsets_size, int is_async)\n",
    "{\n",
    "    struct rb_node *n = proc->free_buffers.rb_node;\n",
    "    struct binder_buffer *buffer;\n",
    "    size_t buffer_size;\n",
    "    struct rb_node *best_fit = NULL;\n",
    "    void *has_page_addr;\n",
    "    void *end_page_addr;\n",
    "    size_t size;\n",
    "    if (proc->vma == NULL) {\n",
    "        return NULL; //虚拟地址空间为空，直接返回\n",
    "    }\n",
    "    size = ALIGN(data_size, sizeof(void *)) + ALIGN(offsets_size, sizeof(void *));\n",
    "    if (size < data_size || size < offsets_size) {\n",
    "        return NULL; //非法的size\n",
    "    }\n",
    "    if (is_async && proc->free_async_space < size + sizeof(struct binder_buffer)) {\n",
    "        return NULL; // 剩余可用的异步空间，小于所需的大小\n",
    "    }\n",
    "    while (n) {  //从binder_buffer的红黑树中查找大小相等的buffer块\n",
    "        buffer = rb_entry(n, struct binder_buffer, rb_node);\n",
    "        buffer_size = binder_buffer_size(proc, buffer);\n",
    "        if (size < buffer_size) {\n",
    "            best_fit = n;\n",
    "            n = n->rb_left;\n",
    "        } else if (size > buffer_size)\n",
    "            n = n->rb_right;\n",
    "        else {\n",
    "            best_fit = n;\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    if (best_fit == NULL) {\n",
    "        return NULL; //内存分配失败，地址空间为空\n",
    "    }\n",
    "    if (n == NULL) {\n",
    "        buffer = rb_entry(best_fit, struct binder_buffer, rb_node);\n",
    "        buffer_size = binder_buffer_size(proc, buffer);\n",
    "    }\n",
    "\n",
    "    has_page_addr =(void *)(((uintptr_t)buffer->data + buffer_size) & PAGE_MASK);\n",
    "    if (n == NULL) {\n",
    "        if (size + sizeof(struct binder_buffer) + 4 >= buffer_size)\n",
    "            buffer_size = size;\n",
    "        else\n",
    "            buffer_size = size + sizeof(struct binder_buffer);\n",
    "    }\n",
    "    end_page_addr =     (void *)PAGE_ALIGN((uintptr_t)buffer->data + buffer_size);\n",
    "    if (end_page_addr > has_page_addr)\n",
    "        end_page_addr = has_page_addr;\n",
    "    if (binder_update_page_range(proc, 1,\n",
    "        (void *)PAGE_ALIGN((uintptr_t)buffer->data), end_page_addr, NULL))\n",
    "        return NULL;\n",
    "    rb_erase(best_fit, &proc->free_buffers);\n",
    "    buffer->free = 0;\n",
    "    binder_insert_allocated_buffer(proc, buffer);\n",
    "    if (buffer_size != size) {\n",
    "        struct binder_buffer *new_buffer = (void *)buffer->data + size;\n",
    "        list_add(&new_buffer->entry, &buffer->entry);\n",
    "        new_buffer->free = 1;\n",
    "        binder_insert_free_buffer(proc, new_buffer);\n",
    "    }\n",
    "\n",
    "    buffer->data_size = data_size;\n",
    "    buffer->offsets_size = offsets_size;\n",
    "    buffer->async_transaction = is_async;\n",
    "    if (is_async) {\n",
    "        proc->free_async_space -= size + sizeof(struct binder_buffer);\n",
    "    }\n",
    "    return buffer;\n",
    "}\n",
    "```\n",
    "\n",
    "- 这里介绍的 binder_alloc_buf 是内存分配函数。除此之外，还有内存释放相关方法：\n",
    "  - binder_free_buf\n",
    "  - binder_delete_free_buffer\n",
    "  - binder_transaction_buffer_release\n",
    "  \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 binder_ioctl\n",
    "- binder_ioctl() 函数负责在两个进程间收发 IPC 数据和 IPC reply 数据\n",
    "  - (1) 文件描述符，是通过 open() 方法打开 Binder Driver 后返回值\n",
    "  - (2) ioctl 命令和数据类型是一体的，不同的命令对应不同的数据类型\n",
    "  \n",
    "![image](binder1_page5.png)\n",
    "\n",
    "```\n",
    "static long binder_ioctl(struct file *filp, unsigned int cmd, unsigned long arg)\n",
    "{\n",
    "    int ret;\n",
    "    struct binder_proc *proc = filp->private_data;\n",
    "    struct binder_thread *thread;  // binder线程\n",
    "    unsigned int size = _IOC_SIZE(cmd);\n",
    "    void __user *ubuf = (void __user *)arg;\n",
    "    //进入休眠状态，直到中断唤醒\n",
    "    ret = wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error < 2);\n",
    "    if (ret)\n",
    "        goto err_unlocked;\n",
    "\n",
    "    binder_lock(__func__);\n",
    "    //获取binder_thread【见2.4.1】\n",
    "    thread = binder_get_thread(proc);\n",
    "    if (thread == NULL) {\n",
    "        ret = -ENOMEM;\n",
    "        goto err;\n",
    "    }\n",
    "\n",
    "    switch (cmd) {\n",
    "    case BINDER_WRITE_READ:  //进行binder的读写操作\n",
    "        ret = binder_ioctl_write_read(filp, cmd, arg, thread); //【见2.4.2】\n",
    "        if (ret)\n",
    "            goto err;\n",
    "        break;\n",
    "    case BINDER_SET_MAX_THREADS: //设置binder最大支持的线程数\n",
    "        if (copy_from_user(&proc->max_threads, ubuf, sizeof(proc->max_threads))) {\n",
    "            ret = -EINVAL;\n",
    "            goto err;\n",
    "        }\n",
    "        break;\n",
    "    case BINDER_SET_CONTEXT_MGR: //成为binder的上下文管理者，也就是ServiceManager成为守护进程\n",
    "        ret = binder_ioctl_set_ctx_mgr(filp);\n",
    "        if (ret)\n",
    "            goto err;\n",
    "        break;\n",
    "    case BINDER_THREAD_EXIT:   //当binder线程退出，释放binder线程\n",
    "        binder_free_thread(proc, thread);\n",
    "        thread = NULL;\n",
    "        break;\n",
    "    case BINDER_VERSION: {  //获取binder的版本号\n",
    "        struct binder_version __user *ver = ubuf;\n",
    "\n",
    "        if (size != sizeof(struct binder_version)) {\n",
    "            ret = -EINVAL;\n",
    "            goto err;\n",
    "        }\n",
    "        if (put_user(BINDER_CURRENT_PROTOCOL_VERSION,\n",
    "                 &ver->protocol_version)) {\n",
    "            ret = -EINVAL;\n",
    "            goto err;\n",
    "        }\n",
    "        break;\n",
    "    }\n",
    "    default:\n",
    "        ret = -EINVAL;\n",
    "        goto err;\n",
    "    }\n",
    "    ret = 0;\n",
    "err:\n",
    "    if (thread)\n",
    "        thread->looper &= ~BINDER_LOOPER_STATE_NEED_RETURN;\n",
    "    binder_unlock(__func__);\n",
    "    wait_event_interruptible(binder_user_error_wait, binder_stop_on_user_error < 2);\n",
    "\n",
    "err_unlocked:\n",
    "    trace_binder_ioctl_done(ret);\n",
    "    return ret;\n",
    "}\n",
    "```\n",
    "\n",
    "#### 2.4.1 binder_get_thread\n",
    "- 从 binder_proc 中查找 binder_thread, 如果当前线程已经加入到 proc 的线程队列则直接返回，如果不存在则创建 binder_thread，并将当前线程添加到当前的 proc\n",
    "\n",
    "```\n",
    "static struct binder_thread *binder_get_thread(struct binder_proc *proc)\n",
    "{\n",
    "    struct binder_thread *thread = NULL;\n",
    "    struct rb_node *parent = NULL;\n",
    "    struct rb_node **p = &proc->threads.rb_node;\n",
    "    while (*p) {  //根据当前进程的pid，从binder_proc中查找相应的binder_thread\n",
    "        parent = *p;\n",
    "        thread = rb_entry(parent, struct binder_thread, rb_node);\n",
    "        if (current->pid < thread->pid)\n",
    "            p = &(*p)->rb_left;\n",
    "        else if (current->pid > thread->pid)\n",
    "            p = &(*p)->rb_right;\n",
    "        else\n",
    "            break;\n",
    "    }\n",
    "    if (*p == NULL) {\n",
    "        thread = kzalloc(sizeof(*thread), GFP_KERNEL); //新建binder_thread结构体\n",
    "        if (thread == NULL)\n",
    "            return NULL;\n",
    "        binder_stats_created(BINDER_STAT_THREAD);\n",
    "        thread->proc = proc;\n",
    "        thread->pid = current->pid;  //保存当前进程(线程)的pid\n",
    "        init_waitqueue_head(&thread->wait);\n",
    "        INIT_LIST_HEAD(&thread->todo);\n",
    "        rb_link_node(&thread->rb_node, parent, p);\n",
    "        rb_insert_color(&thread->rb_node, &proc->threads);\n",
    "        thread->looper |= BINDER_LOOPER_STATE_NEED_RETURN;\n",
    "        thread->return_error = BR_OK;\n",
    "        thread->return_error2 = BR_OK;\n",
    "    }\n",
    "    return thread;\n",
    "}\n",
    "```\n",
    "\n",
    "#### 2.4.2 binder_ioctl_write_read\n",
    "- 对于 ioctl() 方法中，传递进来的命令是 cmd = BINDER_WRITE_READ 时执行该方法，arg 是一个 binder_write_read 结构体\n",
    "\n",
    "```\n",
    "static int binder_ioctl_write_read(struct file *filp,\n",
    "                unsigned int cmd, unsigned long arg,\n",
    "                struct binder_thread *thread)\n",
    "{\n",
    "    int ret = 0;\n",
    "    struct binder_proc *proc = filp->private_data;\n",
    "    unsigned int size = _IOC_SIZE(cmd);\n",
    "    void __user *ubuf = (void __user *)arg;\n",
    "    struct binder_write_read bwr;\n",
    "\n",
    "    if (size != sizeof(struct binder_write_read)) {\n",
    "        ret = -EINVAL;\n",
    "        goto out;\n",
    "    }\n",
    "    if (copy_from_user(&bwr, ubuf, sizeof(bwr))) { //把用户空间数据ubuf拷贝到bwr\n",
    "        ret = -EFAULT;\n",
    "        goto out;\n",
    "    }\n",
    "\n",
    "    if (bwr.write_size > 0) {\n",
    "        //当写缓存中有数据，则执行binder写操作\n",
    "        ret = binder_thread_write(proc, thread,\n",
    "                      bwr.write_buffer, bwr.write_size, &bwr.write_consumed);\n",
    "        trace_binder_write_done(ret);\n",
    "        if (ret < 0) { //当写失败，再将bwr数据写回用户空间，并返回\n",
    "            bwr.read_consumed = 0;\n",
    "            if (copy_to_user(ubuf, &bwr, sizeof(bwr)))\n",
    "                ret = -EFAULT;\n",
    "            goto out;\n",
    "        }\n",
    "    }\n",
    "    if (bwr.read_size > 0) {\n",
    "        //当读缓存中有数据，则执行binder读操作\n",
    "        ret = binder_thread_read(proc, thread,\n",
    "                      bwr.read_buffer, bwr.read_size, &bwr.read_consumed,\n",
    "                      filp->f_flags & O_NONBLOCK);\n",
    "        trace_binder_read_done(ret);\n",
    "        if (!list_empty(&proc->todo))\n",
    "            wake_up_interruptible(&proc->wait); //唤醒等待状态的线程\n",
    "        if (ret < 0) { //当读失败，再将bwr数据写回用户空间，并返回\n",
    "            if (copy_to_user(ubuf, &bwr, sizeof(bwr)))\n",
    "                ret = -EFAULT;\n",
    "            goto out;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if (copy_to_user(ubuf, &bwr, sizeof(bwr))) { //将内核数据bwr拷贝到用户空间ubuf\n",
    "        ret = -EFAULT;\n",
    "        goto out;\n",
    "    }\n",
    "out:\n",
    "    return ret;\n",
    "}\n",
    "```\n",
    "\n",
    "- 对于binder_ioctl_write_read的流程图，如下：\n",
    "![image](binder1_page6.png)\n",
    "\n",
    "- 流程：\n",
    "  - 首先，把用户空间数据 ubuf 拷贝到内核空间 bwr\n",
    "  - 当 bwr 写缓存有数据，则执行 binder_thread_write；当写失败则将 bwr 数据写回用户空间并退出\n",
    "  - 当 bwr 读缓存有数据，则执行 binder_thread_read；当读失败则再将 bwr 数据写回用户空间并退出\n",
    "  - 最后，把内核数据 bwr 拷贝到用户空间 ubuf\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Command 使用场景\n",
    "- ioctl 命令常见命令的使用场景，其中 BINDER_WRITE_READ 最为频繁\n",
    "  - BINDER_WRITE_READ\n",
    "    - Binder 读写交互场景，IPC.talkWithDriver\n",
    "  - BINDER_SET_CONTEXT_MGR\n",
    "    - servicemanager 进程成为上下文管理者，binder_become_context_manager()\n",
    "  - BINDER_SET_MAX_THREADS\n",
    "    - 初始化 ProcessState 对象，open_driver()\n",
    "    - 主动调整参数，ProcessState.setThreadPoolMaxThreadCount()\n",
    "  - BINDER_VERSION\n",
    "    - 初始化 ProcessState 对象，open_driver()\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 小节\n",
    "- binder_init：初始化字符设备\n",
    "- binder_open：打开驱动设备，过程需要持有 binder_main_lock 同步锁\n",
    "- binder_mmap：申请内存空间，该过程需要持有 binder_mmap_lock 同步锁\n",
    "- binder_ioctl：执行相应的 ioctl 操作，该过程需要持有 binder_main_lock 同步锁\n",
    "  - 当处于 binder_thread_read 过程，read_buffer 无数据则释放同步锁，并处于 wait_event_freezable 过程，等有数据到来则唤醒并尝试持有同步锁\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
